{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "%matplotlib widget\n",
    "\n",
    "import sys,os\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "\n",
    "import cvxpy as cp\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from qpth.qp import QPFunction, QPSolvers\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%run BallPaddleSystem.py\n",
    "%run ParametrizedQP.py\n",
    "%run utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = BallPaddleSystem(dt=.05,u_max=2.)\n",
    "ball_x0_min = np.array([0.25, -1.5])\n",
    "ball_x0_max = np.array([1.75, 2.])\n",
    "paddle_x0 = np.array([0.,0.])\n",
    "ball_xg = np.array([1.,0.])\n",
    "N = 20\n",
    "\n",
    "# system = BallPaddleSystem(dt=.1,u_max=10.)\n",
    "# ball_x0_min = np.array([0.05, -10.])\n",
    "# ball_x0_max = np.array([2., 10.])\n",
    "# paddle_x0 = np.array([0.,0.])\n",
    "# ball_xg = np.array([1.,0.])\n",
    "# N = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data of the cost-to-go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_pos = 10\n",
    "dim_vel = 10\n",
    "ball_x0_pos = np.linspace(ball_x0_min[0], ball_x0_max[0], dim_pos)\n",
    "ball_x0_vel = np.linspace(ball_x0_min[1], ball_x0_max[1], dim_vel)\n",
    "BALL_POS, BALL_VEL = np.meshgrid(ball_x0_pos, ball_x0_vel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [########################################] 100.0%\n"
     ]
    }
   ],
   "source": [
    "BALL_VAL = np.zeros(BALL_POS.shape)\n",
    "for i in range(BALL_POS.shape[0]):\n",
    "    for j in range(BALL_POS.shape[1]):\n",
    "        (prob,objective,constraints,var) = system.get_trajectory_miqp(paddle_x0,[BALL_POS[i,j],BALL_VEL[i,j]],ball_xg,N)\n",
    "        prob.solve(solver=cp.CPLEX)\n",
    "        val = objective.value\n",
    "        if val:\n",
    "            BALL_VAL[i,j] = val\n",
    "        else:\n",
    "            BALL_VAL[i,j] = None\n",
    "            \n",
    "        update_progress((i*BALL_POS.shape[1]+j+1)/(BALL_POS.shape[0]*BALL_POS.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save training data\n",
    "np.savez('ball_paddle_values', BALL_VAL=BALL_VAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR load training data\n",
    "data = np.load('ball_paddle_values.npz')\n",
    "BALL_VAL = data['BALL_VAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the data\n",
    "np.nan_to_num(BALL_VAL,copy=False,nan=np.nanmax(BALL_VAL));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e211a53604c74a07b7b211553a901f08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0x7f24aca62710>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.plot_surface(BALL_POS, BALL_VEL, BALL_VAL, rstride=1, cstride=1,\n",
    "                cmap='plasma', edgecolor='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_data = np.vstack((np.reshape(BALL_POS,-1),np.reshape(BALL_VEL,-1))).T\n",
    "z_label = np.expand_dims(np.reshape(BALL_VAL,-1),axis=1)\n",
    "\n",
    "# shuffle it\n",
    "num_data = xy_data.shape[0]\n",
    "indx = np.arange(num_data)\n",
    "np.random.shuffle(indx)\n",
    "\n",
    "xy_data = xy_data[indx,:]\n",
    "z_label = z_label[indx,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a neural network to approximate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 50\n",
    "\n",
    "nn_width = 24\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(2, nn_width),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(nn_width, nn_width),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(nn_width, nn_width),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(nn_width, 1)\n",
    ")\n",
    "model.double()\n",
    "\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "writer = SummaryWriter()\n",
    "n_iter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: move to GPU\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = next(model.parameters()).device\n",
    "xy_data_tensor = torch.from_numpy(xy_data).to(device)\n",
    "z_label_tensor = torch.from_numpy(z_label).to(device)\n",
    "\n",
    "num_epoch = 10000\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    batch_start = 0\n",
    "    while batch_start < num_data:\n",
    "        batch_end = min(num_data-1,batch_start+batch_size)\n",
    "        x = xy_data_tensor[batch_start:batch_end,:]\n",
    "        z = z_label_tensor[batch_start:batch_end,:]\n",
    "        z_pred = model(x)\n",
    "        loss = loss_fn(z_pred, z) / batch_size\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_start += batch_size\n",
    "        n_iter += 1\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"loss: %f\" % loss.item())\n",
    "#         writer.add_scalar('Loss/train', loss.item(), n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find where the neural network over-approximates the most (becomes inadmissible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-26.18005452392986\n"
     ]
    }
   ],
   "source": [
    "(prob,objective,constraints,var) = system.get_adversarial_miqp(model,paddle_x0,ball_x0_min,ball_x0_max,ball_xg,N)\n",
    "prob.solve(solver=cp.CPLEX)\n",
    "\n",
    "worst_input = np.array(var['zb'].value[:,0])\n",
    "\n",
    "print(objective.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPXPARAM_Read_DataCheck                          1\n",
      "Tried aggregator 1 time.\n",
      "QP Presolve eliminated 376 rows and 20 columns.\n",
      "Aggregator did 81 substitutions.\n",
      "Reduced QP has 284 rows, 166 columns, and 2956 nonzeros.\n",
      "Reduced QP objective Q matrix has 19 nonzeros.\n",
      "Presolve time = 0.00 sec. (0.54 ticks)\n",
      "Parallel mode: using up to 32 threads for barrier.\n",
      "Number of nonzeros in lower triangle of A*A' = 9050\n",
      "Using Approximate Minimum Degree ordering\n",
      "Total time for automatic ordering = 0.00 sec. (0.44 ticks)\n",
      "Summary statistics for Cholesky factor:\n",
      "  Threads                   = 32\n",
      "  Rows in Factor            = 284\n",
      "  Integer space required    = 554\n",
      "  Total non-zeros in factor = 10056\n",
      "  Total FP ops to factor    = 541072\n",
      " Itn      Primal Obj        Dual Obj  Prim Inf Upper Inf  Dual Inf          \n",
      "   0   4.8962156e+01  -3.2539202e+05  4.15e+03  2.23e+03  2.38e+05\n",
      "   1  -1.7052292e+01  -3.2448917e+05  3.44e+02  1.85e+02  1.98e+04\n",
      "   2  -1.7845845e+01  -1.0035874e+05  2.02e+01  1.08e+01  1.16e+03\n",
      "   3  -1.7768548e+01  -2.8920391e+03  3.47e-01  1.87e-01  2.94e+01\n",
      "   4  -4.5742747e+01  -5.0541572e+02  4.27e-02  2.29e-02  3.62e+00\n",
      "   5  -6.5964011e+01  -3.2900403e+02  1.69e-02  9.08e-03  1.43e+00\n",
      "   6  -8.1975487e+01  -1.3159527e+02  3.14e-03  1.68e-03  2.69e-01\n",
      "   7  -8.6587866e+01  -9.4920648e+01  5.10e-04  2.74e-04  4.39e-02\n",
      "   8  -8.7403506e+01  -8.9516607e+01  1.27e-04  6.84e-05  1.09e-02\n",
      "   9  -8.7694865e+01  -8.7949548e+01  1.42e-05  7.63e-06  1.22e-03\n",
      "  10  -8.7738340e+01  -8.7752650e+01  5.37e-07  2.88e-07  4.63e-05\n",
      "  11  -8.7741829e+01  -8.7742964e+01  1.56e-08  8.40e-09  1.35e-06\n",
      "  12  -8.7742230e+01  -8.7742355e+01  1.25e-10  3.27e-11  5.17e-09\n",
      "  13  -8.7742282e+01  -8.7742300e+01  8.39e-10  1.05e-14  1.29e-10\n",
      "  14  -8.7742290e+01  -8.7742292e+01  3.93e-09  6.92e-15  1.90e-10\n",
      "  15  -8.7742291e+01  -8.7742291e+01  1.17e-08  1.24e-14  1.19e-11\n",
      "Barrier time = 0.05 sec. (3.45 ticks)\n",
      "\n",
      "Total time on 32 threads = 0.05 sec. (3.45 ticks)\n",
      "-87.74229078505016\n"
     ]
    }
   ],
   "source": [
    "# check if the relaxed problem is far off\n",
    "(prob,objective,constraints,var) = system.get_adversarial_qp(model,paddle_x0,ball_x0_min,ball_x0_max,ball_xg,N)\n",
    "prob.solve(verbose=True,solver=cp.CPLEX)\n",
    "\n",
    "print(objective.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-90.75892779186107\n"
     ]
    }
   ],
   "source": [
    "# and diff solver accurate\n",
    "prob = system.get_adversarial_qp_standard(model,paddle_x0,ball_x0_min,ball_x0_max,ball_xg,N)\n",
    "qp_fun = QPFunction(verbose=False,solver=QPSolvers.CVXPY,check_Q_spd=True)\n",
    "x_adv = qp_fun(prob.Q + 1e-6*torch.eye(prob.num_vars).type(torch.DoubleTensor).to(device), prob.q, prob.G, prob.h, prob.A, prob.b)\n",
    "r = prob.eval_obj(x_adv)\n",
    "\n",
    "print(r.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain the network but with admissibility regularization and check again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 50\n",
    "\n",
    "nn_width = 24\n",
    "admissible_model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(2, nn_width),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(nn_width, nn_width),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(nn_width, nn_width),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(nn_width, 1)\n",
    ")\n",
    "admissible_model.double()\n",
    "\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "# optimizer = torch.optim.SGD(admissible_model.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(admissible_model.parameters(), lr=learning_rate)\n",
    "\n",
    "writer = SummaryWriter()\n",
    "n_iter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.SGD(admissible_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: move to GPU\n",
    "admissible_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = next(admissible_model.parameters()).device\n",
    "xy_data_tensor = torch.from_numpy(xy_data).to(device)\n",
    "z_label_tensor = torch.from_numpy(z_label).to(device)\n",
    "\n",
    "num_epoch = 100\n",
    "\n",
    "qp_fun = QPFunction(verbose=False,solver=QPSolvers.CVXPY,check_Q_spd=True)\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    batch_start = 0\n",
    "    \n",
    "    while batch_start < num_data:\n",
    "        batch_end = min(num_data-1,batch_start+batch_size)\n",
    "        x = xy_data_tensor[batch_start:batch_end,:]\n",
    "        z = z_label_tensor[batch_start:batch_end,:]\n",
    "        z_pred = admissible_model(x)\n",
    "        \n",
    "        prob = system.get_adversarial_qp_standard(admissible_model,paddle_x0,ball_x0_min,ball_x0_max,ball_xg,N)\n",
    "        \n",
    "        QI = 1e-6*torch.eye(prob.num_vars).to(device).type(prob.dtype)\n",
    "        x_adv = qp_fun(prob.Q + QI, prob.q, prob.G, prob.h, prob.A, prob.b)\n",
    "        r = prob.eval_obj(x_adv) * 10.\n",
    "    \n",
    "        reg_loss = F.relu(-r)\n",
    "        fit_loss = loss_fn(z_pred, z) / batch_size \n",
    "    \n",
    "        loss = fit_loss + reg_loss\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_start += batch_size\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "#         print(\"reg: %f\" % reg_loss.item())\n",
    "#         print(\"fit: %f\" % fit_loss.item())\n",
    "#         print(\"loss: %f\" % loss.item())\n",
    "        writer.add_scalar('Admissible/train', loss.item(), n_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying with adversarial activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying the activation-based approach\n",
    "\n",
    "learning_rate = 1e-3\n",
    "batch_size = 50\n",
    "\n",
    "# nn_width = 12\n",
    "# admissible_model = torch.nn.Sequential(\n",
    "#     torch.nn.Linear(2, nn_width),\n",
    "#     torch.nn.ReLU(),\n",
    "#     torch.nn.Linear(nn_width, nn_width),\n",
    "#     torch.nn.ReLU(),\n",
    "#     torch.nn.Linear(nn_width, 1)\n",
    "# )\n",
    "# nn_width = 48\n",
    "# admissible_model = torch.nn.Sequential(\n",
    "#     torch.nn.Linear(2, nn_width),\n",
    "#     torch.nn.ReLU(),\n",
    "#     torch.nn.Linear(nn_width, nn_width),\n",
    "#     torch.nn.ReLU(),\n",
    "#     torch.nn.Linear(nn_width, nn_width),\n",
    "#     torch.nn.ReLU(),\n",
    "#     torch.nn.Linear(nn_width, 1)\n",
    "# )\n",
    "# admissible_model.double()\n",
    "nn_width = 24\n",
    "admissible_model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(2, nn_width),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(nn_width, nn_width),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(nn_width, nn_width),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(nn_width, 1)\n",
    ")\n",
    "\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "# optimizer = torch.optim.SGD(admissible_model.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(admissible_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.SGD(admissible_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: move to GPU\n",
    "admissible_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find an adverserial example\n",
    "with torch.no_grad():\n",
    "    (prob,objective,constraints,var) = system.get_adversarial_miqp(admissible_model,paddle_x0,ball_x0_min,ball_x0_max,ball_xg,N)\n",
    "    prob.solve(solver=cp.CPLEX)\n",
    "    bi = np.array(var['bi'].value)\n",
    "    v = [np.array(v.value) for v in var['v']]\n",
    "    #print(\"adv: %f\" % objective.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = next(admissible_model.parameters()).device\n",
    "xy_data_tensor = torch.from_numpy(xy_data).to(device)\n",
    "z_label_tensor = torch.from_numpy(z_label).to(device)\n",
    "\n",
    "num_epoch = 100\n",
    "\n",
    "qp_fun = QPFunction(verbose=False,solver=QPSolvers.CVXPY,check_Q_spd=True)\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    batch_start = 0\n",
    "    \n",
    "    while batch_start < num_data:\n",
    "        batch_end = min(num_data-1,batch_start+batch_size)\n",
    "        x = xy_data_tensor[batch_start:batch_end,:]\n",
    "        z = z_label_tensor[batch_start:batch_end,:]\n",
    "        z_pred = admissible_model(x)\n",
    "        fit_loss = loss_fn(z_pred, z) / batch_size\n",
    "        \n",
    "#         # find an adverserial example\n",
    "#         with torch.no_grad():\n",
    "#             (prob,objective,constraints,var) = system.get_adversarial_miqp(admissible_model,paddle_x0,ball_x0_min,ball_x0_max,ball_xg,N)\n",
    "#             prob.solve(solver=cp.CPLEX)\n",
    "#             bi = np.array(var['bi'].value)\n",
    "#             v = [np.array(v.value) for v in var['v']]\n",
    "#             #print(\"adv: %f\" % objective.value)\n",
    "            \n",
    "        prob = system.get_adversarial_qp_standard(admissible_model,paddle_x0,ball_x0_min,ball_x0_max,ball_xg,N,bi=bi,v=v)    \n",
    "        QI = 1e-6*torch.eye(prob.num_vars).to(device).type(prob.dtype)\n",
    "        x_adv = qp_fun(prob.Q + QI, prob.q, prob.G, prob.h, prob.A, prob.b)\n",
    "        r = prob.eval_obj(x_adv) * 10.\n",
    "        #print(\"relaxed adv: %f\" % r.item())\n",
    "        reg_loss = F.relu(-r)\n",
    "                \n",
    "        loss = fit_loss + reg_loss\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_start += batch_size\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(\"reg: %f\" % reg_loss.item())\n",
    "        print(\"fit: %f\" % fit_loss.item())\n",
    "        print(\"loss: %f\" % loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(prob,objective,constraints,var) = system.get_adversarial_miqp(admissible_model,paddle_x0,ball_x0_min,ball_x0_max,ball_xg,N)\n",
    "prob.solve(solver=cp.CPLEX)\n",
    "\n",
    "worst_input_admiss = np.array(var['zb'].value[:,0])\n",
    "\n",
    "print(objective.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(prob,objective,constraints,var) = system.get_adversarial_qp(admissible_model,paddle_x0,ball_x0_min,ball_x0_max,ball_xg,N)\n",
    "prob.solve()\n",
    "\n",
    "print(objective.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the samples and the approximated cost-to-go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== NOT ADMISSIBLE ===\")\n",
    "\n",
    "print(\"Neural network\")\n",
    "print(worst_input)\n",
    "with torch.no_grad():\n",
    "    worst_value = model(torch.from_numpy(worst_input).to(device)).cpu().numpy()\n",
    "print(worst_value)\n",
    "\n",
    "print(\"Optimization problem\")\n",
    "print(worst_input)\n",
    "(prob,objective,constraints,var) = system.get_trajectory_miqp(paddle_x0,worst_input,ball_xg,N)\n",
    "prob.solve(solver=cp.CPLEX)\n",
    "worst_opt_val = objective.value\n",
    "print(worst_opt_val)\n",
    "\n",
    "print(\"Optimization of closest on grid\")\n",
    "worst_input_grid = [find_nearest(ball_x0_pos,worst_input[0]),find_nearest(ball_x0_vel,worst_input[1])]\n",
    "print(worst_input_grid)\n",
    "(prob,objective,constraints,var) = system.get_trajectory_miqp(paddle_x0,worst_input_grid,ball_xg,N)\n",
    "prob.solve(solver=cp.CPLEX)\n",
    "worst_opt_val_grid = objective.value\n",
    "print(worst_opt_val_grid)\n",
    "\n",
    "print(\"Neural network of closest on grid\")\n",
    "print(worst_input_grid)\n",
    "with torch.no_grad():\n",
    "    worst_value_grid = model(torch.from_numpy(np.array(worst_input_grid)).to(device)).cpu().numpy()\n",
    "print(worst_value_grid)\n",
    "\n",
    "print(\"\\n=== ADMISSIBLE ===\")\n",
    "\n",
    "print(\"Admissible neural network (same input as nonadmissible)\")\n",
    "print(worst_input)\n",
    "with torch.no_grad():\n",
    "    worst_value_same = admissible_model(torch.from_numpy(worst_input).to(device)).cpu().numpy()\n",
    "print(worst_value_same)\n",
    "\n",
    "print(\"Admissible neural network (worst for this network)\")\n",
    "print(worst_input_admiss)\n",
    "with torch.no_grad():\n",
    "    worst_value_admiss = admissible_model(torch.from_numpy(worst_input_admiss).to(device)).cpu().numpy()\n",
    "print(worst_value_admiss)\n",
    "\n",
    "print(\"Optimization problem\")\n",
    "print(worst_input_admiss)\n",
    "(prob,objective,constraints,var) = system.get_trajectory_miqp(paddle_x0,worst_input_admiss,ball_xg,N)\n",
    "prob.solve(solver=cp.CPLEX)\n",
    "worst_opt_val_admiss = objective.value\n",
    "print(worst_opt_val_admiss)\n",
    "\n",
    "print(\"Optimization of closest on grid\")\n",
    "worst_input_grid_admiss = [find_nearest(ball_x0_pos,worst_input_admiss[0]),find_nearest(ball_x0_vel,worst_input_admiss[1])]\n",
    "print(worst_input_grid_admiss)\n",
    "(prob,objective,constraints,var) = system.get_trajectory_miqp(paddle_x0,worst_input_grid_admiss,ball_xg,N)\n",
    "prob.solve(solver=cp.CPLEX)\n",
    "worst_opt_val_admiss_grid = objective.value\n",
    "print(worst_opt_val_admiss_grid)\n",
    "\n",
    "print(\"Neural network of closest on grid\")\n",
    "print(worst_input_grid_admiss)\n",
    "with torch.no_grad():\n",
    "    worst_value_admiss_grid = admissible_model(torch.from_numpy(np.array(worst_input_grid_admiss)).to(device)).cpu().numpy()\n",
    "print(worst_value_admiss_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    z_pred = model(torch.from_numpy(xy_data).to(device)).cpu().numpy()\n",
    "#     z_pred_admiss = admissible_model(torch.from_numpy(xy_data).to(device)).cpu().numpy()\n",
    "    \n",
    "# unshuffle\n",
    "z_pred = z_pred[[np.argwhere(indx == i)[0,0] for i in np.arange(num_data)]]\n",
    "Z_pred = np.reshape(z_pred,BALL_POS.shape)\n",
    "\n",
    "# z_pred_admiss = z_pred_admiss[[np.argwhere(indx == i)[0,0] for i in np.arange(num_data)]]\n",
    "# Z_pred_admiss = np.reshape(z_pred_admiss,BALL_POS.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3863fddae2a74723b502420d443862c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0x7f24ac7e4668>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.plot_surface(BALL_POS, BALL_VEL, BALL_VAL, rstride=1, cstride=1,\n",
    "                cmap='plasma', edgecolor='none')\n",
    "ax.plot_surface(BALL_POS, BALL_VEL, Z_pred, rstride=1, cstride=1,\n",
    "                cmap='viridis', edgecolor='none')\n",
    "# ax.plot_surface(BALL_POS, BALL_VEL, Z_pred_admiss, rstride=1, cstride=1,\n",
    "#                 cmap='Greys', edgecolor='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.plot_surface(BALL_POS, BALL_VEL, BALL_VAL - Z_pred_admiss, rstride=1, cstride=1,\n",
    "                cmap='plasma', edgecolor='none')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
